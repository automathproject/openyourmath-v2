{
  "uuid": "CXE4",
  "title": "Rétropropagation à une variable",
  "chapter": "Autre",
  "subchapter": "Autre",
  "theme": "réseaux de neurones",
  "difficulty": null,
  "author": "Maxime NGUYEN",
  "organization": "AMSCC",
  "video_id": "",
  "created_at": "2024-12-02",
  "updated_at": "2025-08-25T08:56:31.015Z",
  "content": [
    {
      "id": "block_1",
      "type": "text",
      "latex": "Vous allez travailler avec un réseau de neurones à une couche cachée, conçu pour effectuer une tâche de prédiction simple. \n\t\n\t\n\t\n\t\\textbf{Description du réseau}\n\t\n\t\\begin{itemize}\n\t\t\\item \\textbf{Entrée :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\( x \\in \\mathbb{R} \\) (scalaire)\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Couche cachée (2 neurones) :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\textbf{Neurone caché 1 :}\n\t\t\t\\begin{itemize}\n\t\t\t\t\\item Poids : \\( w_1 = 0{,}15 \\)\n\t\t\t\t\\item Biais : \\( b_1 = 0{,}35 \\)\n\t\t\t\\end{itemize}\n\t\t\t\\item \\textbf{Neurone caché 2 :}\n\t\t\t\\begin{itemize}\n\t\t\t\t\\item Poids : \\( w_2 = 0{,}20 \\)\n\t\t\t\t\\item Biais : \\( b_2 = 0{,}35 \\)\n\t\t\t\\end{itemize}\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Couche de sortie (1 neurone) :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\textbf{Neurone de sortie :}\n\t\t\t\\begin{itemize}\n\t\t\t\t\\item Poids : \\( w_3 = 0{,}40 \\) (connecté au neurone caché 1)\n\t\t\t\t\\item Poids : \\( w_4 = 0{,}45 \\) (connecté au neurone caché 2)\n\t\t\t\t\\item Biais : \\( b_3 = 0{,}60 \\)\n\t\t\t\\end{itemize}\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Fonctions d'activation :}\n\t\t\\begin{itemize}\n\t\t\t\\item Fonction sigmoïde : \\( \\sigma(z) = \\dfrac{1}{1 + e^{-z}} \\)\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Fonction de coût :}\n\t\t\\begin{itemize}\n\t\t\t\\item Erreur quadratique moyenne : \\( E = \\dfrac{1}{2}(y - \\hat{y})^2 \\)\n\t\t\\end{itemize}\n\t\t\n\t\t\\item \\textbf{Données :}\n\t\t\\begin{itemize}\n\t\t\t\\item \\textbf{Entrée :} \\( x = 0{,}05 \\)\n\t\t\t\\item \\textbf{Sortie cible :} \\( y = 0{,}01 \\)\n\t\t\\end{itemize}\n\t\\end{itemize}",
      "html": "<p>Vous allez travailler avec un réseau de neurones à une couche cachée, conçu pour effectuer une tâche de prédiction simple.</p>\n<p><strong>Description du réseau</strong></p>\n<ul>\n<li><p><strong>Entrée :</strong></p>\n<ul>\n<li><p><span class=\"math inline\">\\(x \\in \\mathbb{R}\\)</span> (scalaire)</p></li>\n</ul></li>\n<li><p><strong>Couche cachée (2 neurones) :</strong></p>\n<ul>\n<li><p><strong>Neurone caché 1 :</strong></p>\n<ul>\n<li><p>Poids : <span class=\"math inline\">\\(w_1 = 0{,}15\\)</span></p></li>\n<li><p>Biais : <span class=\"math inline\">\\(b_1 = 0{,}35\\)</span></p></li>\n</ul></li>\n<li><p><strong>Neurone caché 2 :</strong></p>\n<ul>\n<li><p>Poids : <span class=\"math inline\">\\(w_2 = 0{,}20\\)</span></p></li>\n<li><p>Biais : <span class=\"math inline\">\\(b_2 = 0{,}35\\)</span></p></li>\n</ul></li>\n</ul></li>\n<li><p><strong>Couche de sortie (1 neurone) :</strong></p>\n<ul>\n<li><p><strong>Neurone de sortie :</strong></p>\n<ul>\n<li><p>Poids : <span class=\"math inline\">\\(w_3 = 0{,}40\\)</span> (connecté au neurone caché 1)</p></li>\n<li><p>Poids : <span class=\"math inline\">\\(w_4 = 0{,}45\\)</span> (connecté au neurone caché 2)</p></li>\n<li><p>Biais : <span class=\"math inline\">\\(b_3 = 0{,}60\\)</span></p></li>\n</ul></li>\n</ul></li>\n<li><p><strong>Fonctions d’activation :</strong></p>\n<ul>\n<li><p>Fonction sigmoïde : <span class=\"math inline\">\\(\\sigma(z) = \\dfrac{1}{1 + e^{-z}}\\)</span></p></li>\n</ul></li>\n<li><p><strong>Fonction de coût :</strong></p>\n<ul>\n<li><p>Erreur quadratique moyenne : <span class=\"math inline\">\\(E = \\dfrac{1}{2}(y - \\hat{y})^2\\)</span></p></li>\n</ul></li>\n<li><p><strong>Données :</strong></p>\n<ul>\n<li><p><strong>Entrée :</strong> <span class=\"math inline\">\\(x = 0{,}05\\)</span></p></li>\n<li><p><strong>Sortie cible :</strong> <span class=\"math inline\">\\(y = 0{,}01\\)</span></p></li>\n</ul></li>\n</ul>",
      "order": 1
    },
    {
      "id": "block_2",
      "type": "question",
      "latex": "Calculer les sorties des neurones de la couche cachée (\\( h_1 \\) et \\( h_2 \\)).",
      "html": "<p>Calculer les sorties des neurones de la couche cachée (<span class=\"math inline\">\\(h_1\\)</span> et <span class=\"math inline\">\\(h_2\\)</span>).</p>",
      "order": 2
    },
    {
      "id": "block_3",
      "type": "indication",
      "latex": "",
      "html": "",
      "order": 3
    },
    {
      "id": "block_4",
      "type": "reponse",
      "latex": "Neurone caché 1 : \n    \t\\begin{align*}\n    \t\\text{Entrée nette : } & net_{h1} = w_1 \\cdot x + b_1 \\\\\n    \t& net_{h1} = 0{,}15 \\times 0{,}05 + 0{,}35 = 0{,}3575 \\\\\n    \t\\text{Sortie : } & h_1 = \\sigma(net_{h1}) = \\dfrac{1}{1 + e^{-0{,}3575}} \\approx 0{,}5889\n    \t\\end{align*}\n    \t\n    \t\n    \tNeurone caché 2 :\n    \t\n    \t\n    \t\\begin{align*}\n    \t\\text{Entrée nette : } & net_{h2} = w_2 \\cdot x + b_2 \\\\\n    \t& net_{h2} = 0{,}20 \\times 0{,}05 + 0{,}35 = 0{,}36 \\\\\n    \t\\text{Sortie : } & h_2 = \\sigma(net_{h2}) = \\dfrac{1}{1 + e^{-0{,}36}} \\approx 0{,}5890\n    \t\\end{align*}",
      "html": "<p>Neurone caché 1 :\n<span class=\"math display\">\\[\\begin{align*}\n        \\text{Entrée nette : } &amp; net_{h1} = w_1 \\cdot x + b_1 \\\\\n        &amp; net_{h1} = 0{,}15 \\times 0{,}05 + 0{,}35 = 0{,}3575 \\\\\n        \\text{Sortie : } &amp; h_1 = \\sigma(net_{h1}) = \\dfrac{1}{1 + e^{-0{,}3575}} \\approx 0{,}5889\n        \\end{align*}\\]</span></p>\n<p>Neurone caché 2 :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\text{Entrée nette : } &amp; net_{h2} = w_2 \\cdot x + b_2 \\\\\n        &amp; net_{h2} = 0{,}20 \\times 0{,}05 + 0{,}35 = 0{,}36 \\\\\n        \\text{Sortie : } &amp; h_2 = \\sigma(net_{h2}) = \\dfrac{1}{1 + e^{-0{,}36}} \\approx 0{,}5890\n        \\end{align*}\\]</span></p>",
      "order": 4
    },
    {
      "id": "block_5",
      "type": "question",
      "latex": "Calculer la sortie du neurone de sortie (\\( \\hat{y} \\)).",
      "html": "<p>Calculer la sortie du neurone de sortie (<span class=\"math inline\">\\(\\hat{y}\\)</span>).</p>",
      "order": 5
    },
    {
      "id": "block_6",
      "type": "indication",
      "latex": "",
      "html": "",
      "order": 6
    },
    {
      "id": "block_7",
      "type": "reponse",
      "latex": "\\begin{align*}\n    \t\\text{Entrée nette : } & net_o = w_3 \\cdot h_1 + w_4 \\cdot h_2 + b_3 \\\\\n    \t& net_o = 0{,}40 \\times 0{,}5889 + 0{,}45 \\times 0{,}5890 + 0{,}60 \\\\\n    \t& net_o = 0{,}2356 + 0{,}2650 + 0{,}60 = 1{,}1006 \\\\\n    \t\\text{Sortie : } & \\hat{y} = \\sigma(net_o) = \\dfrac{1}{1 + e^{-1{,}1006}} \\approx 0{,}7507\n    \t\\end{align*}",
      "html": "<p><span class=\"math display\">\\[\\begin{align*}\n        \\text{Entrée nette : } &amp; net_o = w_3 \\cdot h_1 + w_4 \\cdot h_2 + b_3 \\\\\n        &amp; net_o = 0{,}40 \\times 0{,}5889 + 0{,}45 \\times 0{,}5890 + 0{,}60 \\\\\n        &amp; net_o = 0{,}2356 + 0{,}2650 + 0{,}60 = 1{,}1006 \\\\\n        \\text{Sortie : } &amp; \\hat{y} = \\sigma(net_o) = \\dfrac{1}{1 + e^{-1{,}1006}} \\approx 0{,}7507\n        \\end{align*}\\]</span></p>",
      "order": 7
    },
    {
      "id": "block_8",
      "type": "question",
      "latex": "Calculer l'erreur du réseau en utilisant la fonction de coût.",
      "html": "<p>Calculer l’erreur du réseau en utilisant la fonction de coût.</p>",
      "order": 8
    },
    {
      "id": "block_9",
      "type": "reponse",
      "latex": "\\begin{align*}\n    \tE = \\dfrac{1}{2}(y - \\hat{y})^2 = \\dfrac{1}{2}(0{,}01 - 0{,}7507)^2 = \\dfrac{1}{2}(-0{,}7407)^2 \\approx 0{,}2741\n    \t\\end{align*}",
      "html": "<p><span class=\"math display\">\\[\\begin{align*}\n        E = \\dfrac{1}{2}(y - \\hat{y})^2 = \\dfrac{1}{2}(0{,}01 - 0{,}7507)^2 = \\dfrac{1}{2}(-0{,}7407)^2 \\approx 0{,}2741\n        \\end{align*}\\]</span></p>",
      "order": 9
    },
    {
      "id": "block_10",
      "type": "question",
      "latex": "Calculer les gradients des poids \\( w_3 \\) et \\( w_4 \\) de la couche de sortie  les gradients des poids \\( w_1 \\) et \\( w_2 \\) de la couche cachée.",
      "html": "<p>Calculer les gradients des poids <span class=\"math inline\">\\(w_3\\)</span> et <span class=\"math inline\">\\(w_4\\)</span> de la couche de sortie les gradients des poids <span class=\"math inline\">\\(w_1\\)</span> et <span class=\"math inline\">\\(w_2\\)</span> de la couche cachée.</p>",
      "order": 10
    },
    {
      "id": "block_11",
      "type": "reponse",
      "latex": "Calcul de l'erreur locale au neurone de sortie (\\( \\delta_o \\)) :\n    \t\n    \t\n    \t\\begin{align*}\n    \t\\delta_o = \\dfrac{\\partial E}{\\partial net_o} = \\dfrac{\\partial E}{\\partial \\hat{y}} \\cdot \\dfrac{\\partial \\hat{y}}{\\partial net_o} \\\\\n    \t\\dfrac{\\partial E}{\\partial \\hat{y}} = \\hat{y} - y = 0{,}7507 - 0{,}01 = 0{,}7407 \\\\\n    \t\\dfrac{\\partial \\hat{y}}{\\partial net_o} = \\hat{y}(1 - \\hat{y}) = 0{,}7507 \\times 0{,}2493 \\approx 0{,}1875 \\\\\n    \t\\delta_o = 0{,}7407 \\times 0{,}1875 \\approx 0{,}1389\n    \t\\end{align*}\n    \t\n    \t\n    \tCalcul des gradients des poids :\n    \t\n    \t\n    \t\\begin{align*}\n    \t\\dfrac{\\partial E}{\\partial w_3} = \\delta_o \\cdot h_1 = 0{,}1389 \\times 0{,}5889 \\approx 0{,}0817 \\\\\n    \t\\dfrac{\\partial E}{\\partial w_4} = \\delta_o \\cdot h_2 = 0{,}1389 \\times 0{,}5890 \\approx 0{,}0818\n    \t\\end{align*}\n    \t\n    \t\n    \tCalcul des gradients des poids \\( w_1 \\) et \\( w_2 \\)\n    \t\n    \tCalcul des erreurs locales aux neurones cachés (\\( \\delta_{h1} \\) et \\( \\delta_{h2} \\)) :\n    \t\n    \t\n    \t\\begin{align*}\n    \t\\delta_{h1} = \\delta_o \\cdot w_3 \\cdot h_1 (1 - h_1) \\\\\n    \t& = 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times (1 - 0{,}5889) \\\\\n    \t& \\approx 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times 0{,}4111 \\approx 0{,}0134 \\\\\n    \t\\delta_{h2} = \\delta_o \\cdot w_4 \\cdot h_2 (1 - h_2) \\\\\n    \t& = 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times (1 - 0{,}5890) \\\\\n    \t& \\approx 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times 0{,}4110 \\approx 0{,}0150\n    \t\\end{align*}\n    \t\n    \t\n    \tCalcul des gradients des poids :\n    \t\n    \t\n    \t\\begin{align*}\n    \t\\dfrac{\\partial E}{\\partial w_1} = \\delta_{h1} \\cdot x = 0{,}0134 \\times 0{,}05 \\approx 0{,}0007 \\\\\n    \t\\dfrac{\\partial E}{\\partial w_2} = \\delta_{h2} \\cdot x = 0{,}0150 \\times 0{,}05 \\approx 0{,}0008\n    \t\\end{align*}",
      "html": "<p>Calcul de l’erreur locale au neurone de sortie (<span class=\"math inline\">\\(\\delta_o\\)</span>) :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\delta_o = \\dfrac{\\partial E}{\\partial net_o} = \\dfrac{\\partial E}{\\partial \\hat{y}} \\cdot \\dfrac{\\partial \\hat{y}}{\\partial net_o} \\\\\n        \\dfrac{\\partial E}{\\partial \\hat{y}} = \\hat{y} - y = 0{,}7507 - 0{,}01 = 0{,}7407 \\\\\n        \\dfrac{\\partial \\hat{y}}{\\partial net_o} = \\hat{y}(1 - \\hat{y}) = 0{,}7507 \\times 0{,}2493 \\approx 0{,}1875 \\\\\n        \\delta_o = 0{,}7407 \\times 0{,}1875 \\approx 0{,}1389\n        \\end{align*}\\]</span></p>\n<p>Calcul des gradients des poids :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\dfrac{\\partial E}{\\partial w_3} = \\delta_o \\cdot h_1 = 0{,}1389 \\times 0{,}5889 \\approx 0{,}0817 \\\\\n        \\dfrac{\\partial E}{\\partial w_4} = \\delta_o \\cdot h_2 = 0{,}1389 \\times 0{,}5890 \\approx 0{,}0818\n        \\end{align*}\\]</span></p>\n<p>Calcul des gradients des poids <span class=\"math inline\">\\(w_1\\)</span> et <span class=\"math inline\">\\(w_2\\)</span></p>\n<p>Calcul des erreurs locales aux neurones cachés (<span class=\"math inline\">\\(\\delta_{h1}\\)</span> et <span class=\"math inline\">\\(\\delta_{h2}\\)</span>) :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\delta_{h1} = \\delta_o \\cdot w_3 \\cdot h_1 (1 - h_1) \\\\\n        &amp; = 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times (1 - 0{,}5889) \\\\\n        &amp; \\approx 0{,}1389 \\times 0{,}40 \\times 0{,}5889 \\times 0{,}4111 \\approx 0{,}0134 \\\\\n        \\delta_{h2} = \\delta_o \\cdot w_4 \\cdot h_2 (1 - h_2) \\\\\n        &amp; = 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times (1 - 0{,}5890) \\\\\n        &amp; \\approx 0{,}1389 \\times 0{,}45 \\times 0{,}5890 \\times 0{,}4110 \\approx 0{,}0150\n        \\end{align*}\\]</span></p>\n<p>Calcul des gradients des poids :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        \\dfrac{\\partial E}{\\partial w_1} = \\delta_{h1} \\cdot x = 0{,}0134 \\times 0{,}05 \\approx 0{,}0007 \\\\\n        \\dfrac{\\partial E}{\\partial w_2} = \\delta_{h2} \\cdot x = 0{,}0150 \\times 0{,}05 \\approx 0{,}0008\n        \\end{align*}\\]</span></p>",
      "order": 11
    },
    {
      "id": "block_12",
      "type": "question",
      "latex": "Avec un taux d'apprentissage \\( \\eta = 0{,}5 \\), mettre à jour tous les poids du réseau.",
      "html": "<p>Avec un taux d’apprentissage <span class=\"math inline\">\\(\\eta = 0{,}5\\)</span>, mettre à jour tous les poids du réseau.</p>",
      "order": 12
    },
    {
      "id": "block_13",
      "type": "reponse",
      "latex": "Avec \\( \\eta = 0{,}5 \\) :\n    \t\n    \t- Mise à jour des poids de la couche de sortie :\n    \t\n    \t\n    \t\\begin{align*}\n    \tw_3^{\\text{nouveau}} = w_3^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_3} = 0{,}40 - 0{,}5 \\times 0{,}0817 = 0{,}3592 \\\\\n    \tw_4^{\\text{nouveau}} = w_4^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_4} = 0{,}45 - 0{,}5 \\times 0{,}0818 = 0{,}4091\n    \t\\end{align*}\n    \t\n    \t\n    \t- Mise à jour des poids de la couche cachée :\n    \t\n    \t\n    \t\\begin{align*}\n    \tw_1^{\\text{nouveau}} = w_1^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_1} = 0{,}15 - 0{,}5 \\times 0{,}0007 = 0{,}1497 \\\\\n    \tw_2^{\\text{nouveau}} = w_2^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_2} = 0{,}20 - 0{,}5 \\times 0{,}0008 = 0{,}1996\n    \t\\end{align*}",
      "html": "<p>Avec <span class=\"math inline\">\\(\\eta = 0{,}5\\)</span> :</p>\n<p>- Mise à jour des poids de la couche de sortie :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        w_3^{\\text{nouveau}} = w_3^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_3} = 0{,}40 - 0{,}5 \\times 0{,}0817 = 0{,}3592 \\\\\n        w_4^{\\text{nouveau}} = w_4^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_4} = 0{,}45 - 0{,}5 \\times 0{,}0818 = 0{,}4091\n        \\end{align*}\\]</span></p>\n<p>- Mise à jour des poids de la couche cachée :</p>\n<p><span class=\"math display\">\\[\\begin{align*}\n        w_1^{\\text{nouveau}} = w_1^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_1} = 0{,}15 - 0{,}5 \\times 0{,}0007 = 0{,}1497 \\\\\n        w_2^{\\text{nouveau}} = w_2^{\\text{ancien}} - \\eta \\dfrac{\\partial E}{\\partial w_2} = 0{,}20 - 0{,}5 \\times 0{,}0008 = 0{,}1996\n        \\end{align*}\\]</span></p>",
      "order": 13
    }
  ],
  "artifacts": {
    "tikz": [],
    "geogebra": [],
    "code": [],
    "video": null
  },
  "source_hash": "f91d6ea5cca39316fe4f03b07cf6dd5bcd4031cc5162228d1b8a995df967e061"
}