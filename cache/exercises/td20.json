{
  "uuid": "td20",
  "title": "Loi Gamma",
  "chapter": "",
  "subchapter": "",
  "theme": "",
  "difficulty": null,
  "author": "A. Guyader",
  "organization": "",
  "video_id": "",
  "created_at": "2025-03-20",
  "updated_at": "2025-08-23T12:07:56.501Z",
  "content": [
    {
      "id": "block_1",
      "type": "text",
      "latex": "On dit que $X$ suit une loi Gamma de paramètres $p$ et $\\theta$ ($p > 0$, $\\theta > 0$), notée $\\gamma(p, \\theta)$, si sa densité (par rapport à la mesure de Lebesgue) est : \n$$\nf(x) = \\frac{\\theta^p}{\\Gamma(p)} x^{p-1} \\exp(-\\theta x)\\mathbf{1}_{[0,+\\infty[}(x),\n$$\nou de façon équivalente, si sa fonction caractéristique vaut \n$$\n\\Phi_X(t) = \\frac{1}{(1-it/\\theta)^p}\n$$\npour tout réel $t$. On rappelle les propriétés suivantes de la fonction Gamma :\n$$\n\\forall\\alpha > 0,\\,\\Gamma(\\alpha) = \\int_0^{\\infty} x^{\\alpha-1} \\exp(-x)dx,\\,\\,\\, \\\\\n\\Gamma(\\alpha + 1) = \\alpha\\Gamma(\\alpha),\\,\\,\n\\Gamma(1/2) = \\sqrt{\\pi}.\n$$",
      "html": "<p>On dit que <span>\\(X\\)</span> suit une loi Gamma de paramètres <span>\\(p\\)</span> et <span>\\(\\theta\\)</span> (<span>\\(p &gt; 0\\)</span>, <span>\\(\\theta &gt; 0\\)</span>), notée <span>\\(\\gamma(p, \\theta)\\)</span>, si sa densité (par rapport à la mesure de Lebesgue) est :\n<span>\\[f(x) = \\frac{\\theta^p}{\\Gamma(p)} x^{p-1} \\exp(-\\theta x)\\mathbf{1}_{[0,+\\infty[}(x),\\]</span>\nou de façon équivalente, si sa fonction caractéristique vaut\n<span>\\[\\Phi_X(t) = \\frac{1}{(1-it/\\theta)^p}\\]</span>\npour tout réel <span>\\(t\\)</span>. On rappelle les propriétés suivantes de la fonction Gamma :\n<span>\\[\\forall\\alpha &gt; 0,\\,\\Gamma(\\alpha) = \\int_0^{\\infty} x^{\\alpha-1} \\exp(-x)dx,\\,\\,\\, \\\\\n\\Gamma(\\alpha + 1) = \\alpha\\Gamma(\\alpha),\\,\\,\n\\Gamma(1/2) = \\sqrt{\\pi}.\\]</span></p>",
      "order": 1
    },
    {
      "id": "block_2",
      "type": "question",
      "latex": "Vérifier que la loi $\\gamma(p, \\theta)$ est bien une loi de probabilité.",
      "html": "<p>Vérifier que la loi <span>\\(\\gamma(p, \\theta)\\)</span> est bien une loi de probabilité.</p>",
      "order": 2
    },
    {
      "id": "block_3",
      "type": "reponse",
      "latex": "Comme $f$ est positive, il suffit de vérifier que $\\int_{\\mathbb{R}} f(x) dx = 1$. Ceci s'obtient en faisant le changement de variable $y = \\theta x$ :\n\\begin{align*}\n\\int_{\\mathbb{R}} f(x) dx &= \\int_{0}^{\\infty} \\frac{(\\theta x)^{p-1}}{\\Gamma(p)}e^{-\\theta x} \\theta dx \\\\\n&= \\frac{1}{\\Gamma(p)}\\int_{0}^{\\infty} y^{p-1}e^{-y} dy \\\\\n&= 1.\n\\end{align*}",
      "html": "<p>Comme <span>\\(f\\)</span> est positive, il suffit de vérifier que <span>\\(\\int_{\\mathbb{R}} f(x) dx = 1\\)</span>. Ceci s’obtient en faisant le changement de variable <span>\\(y = \\theta x\\)</span> :\n<span>\\[\\begin{align*}\n\\int_{\\mathbb{R}} f(x) dx &amp;= \\int_{0}^{\\infty} \\frac{(\\theta x)^{p-1}}{\\Gamma(p)}e^{-\\theta x} \\theta dx \\\\\n&amp;= \\frac{1}{\\Gamma(p)}\\int_{0}^{\\infty} y^{p-1}e^{-y} dy \\\\\n&amp;= 1.\n\\end{align*}\\]</span></p>",
      "order": 3
    },
    {
      "id": "block_4",
      "type": "question",
      "latex": "Calculer $E(X^k)$ pour $k \\geq 1$. En déduire que $E(X) = \\frac{p}{\\theta}$ et $\\text{Var}(X) = \\frac{p}{\\theta^2}$.",
      "html": "<p>Calculer <span>\\(E(X^k)\\)</span> pour <span>\\(k \\geq 1\\)</span>. En déduire que <span>\\(E(X) = \\frac{p}{\\theta}\\)</span> et <span>\\(\\text{Var}(X) = \\frac{p}{\\theta^2}\\)</span>.</p>",
      "order": 4
    },
    {
      "id": "block_5",
      "type": "reponse",
      "latex": "De la même façon que plus haut, on a \n\\begin{align*}\nE(X^k) &= \\int_{\\mathbb{R}} x^k f(x) dx \\\\\n&= \\frac{1}{\\theta^k\\Gamma(p)}\\int_{0}^{\\infty} (\\theta x)^{k+p-1}e^{-\\theta x} \\theta dx \\\\\n&= \\frac{\\Gamma(k+p)}{\\theta^k\\Gamma(p)}.\n\\end{align*}\nAinsi, on a \n\\begin{align*}\nE(X) &= \\frac{\\Gamma(p+1)}{\\theta\\Gamma(p)} = \\frac{p}{\\theta} \\\\\nE(X^2) &= \\frac{\\Gamma(p+2)}{\\theta^2\\Gamma(p)} = \\frac{p(p+1)}{\\theta^2} \\\\\n\\text{Var}(X) &= E(X^2) - (E(X))^2 = \\theta^{-2}(p(p+1) - p^2) = \\frac{p}{\\theta^2}.\n\\end{align*}",
      "html": "<p>De la même façon que plus haut, on a\n<span>\\[\\begin{align*}\nE(X^k) &amp;= \\int_{\\mathbb{R}} x^k f(x) dx \\\\\n&amp;= \\frac{1}{\\theta^k\\Gamma(p)}\\int_{0}^{\\infty} (\\theta x)^{k+p-1}e^{-\\theta x} \\theta dx \\\\\n&amp;= \\frac{\\Gamma(k+p)}{\\theta^k\\Gamma(p)}.\n\\end{align*}\\]</span>\nAinsi, on a\n<span>\\[\\begin{align*}\nE(X) &amp;= \\frac{\\Gamma(p+1)}{\\theta\\Gamma(p)} = \\frac{p}{\\theta} \\\\\nE(X^2) &amp;= \\frac{\\Gamma(p+2)}{\\theta^2\\Gamma(p)} = \\frac{p(p+1)}{\\theta^2} \\\\\n\\text{Var}(X) &amp;= E(X^2) - (E(X))^2 = \\theta^{-2}(p(p+1) - p^2) = \\frac{p}{\\theta^2}.\n\\end{align*}\\]</span></p>",
      "order": 5
    },
    {
      "id": "block_6",
      "type": "question",
      "latex": "Soit $Y$ de loi $\\mathcal{N}(0, 1)$. Calculer la densité de $Y^2$. En déduire que $\\gamma(1/2, 1/2) = \\chi^2(1)$.",
      "html": "<p>Soit <span>\\(Y\\)</span> de loi <span>\\(\\mathcal{N}(0, 1)\\)</span>. Calculer la densité de <span>\\(Y^2\\)</span>. En déduire que <span>\\(\\gamma(1/2, 1/2) = \\chi^2(1)\\)</span>.</p>",
      "order": 6
    },
    {
      "id": "block_7",
      "type": "reponse",
      "latex": "Pour toute fonction $\\Psi$ borélienne bornée, \n\\begin{align*}\nE(\\Psi(Y^2)) &= \\frac{1}{\\sqrt{2\\pi}} \\int_{\\mathbb{R}} \\Psi(y^2)e^{-y^2/2} dy\\\\\n&= \\frac{1}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\Psi(y^2)y^{-1}e^{-y^2/2} \\cdot 2y dy\\\\\n&= \\frac{1}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\Psi(u)u^{-1/2}e^{-u/2} du,\n\\end{align*}\nen posant $u = y^2$. Comme $1/\\sqrt{2\\pi} = 1/(\\sqrt{2}\\Gamma(1/2))$, on a $Y^2 \\sim \\gamma(1/2, 1/2)$. Par ailleurs, on sait que $Y^2 \\sim \\chi^2(1)$ par définition.",
      "html": "<p>Pour toute fonction <span>\\(\\Psi\\)</span> borélienne bornée,\n<span>\\[\\begin{align*}\nE(\\Psi(Y^2)) &amp;= \\frac{1}{\\sqrt{2\\pi}} \\int_{\\mathbb{R}} \\Psi(y^2)e^{-y^2/2} dy\\\\\n&amp;= \\frac{1}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\Psi(y^2)y^{-1}e^{-y^2/2} \\cdot 2y dy\\\\\n&amp;= \\frac{1}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\Psi(u)u^{-1/2}e^{-u/2} du,\n\\end{align*}\\]</span>\nen posant <span>\\(u = y^2\\)</span>. Comme <span>\\(1/\\sqrt{2\\pi} = 1/(\\sqrt{2}\\Gamma(1/2))\\)</span>, on a <span>\\(Y^2 \\sim \\gamma(1/2, 1/2)\\)</span>. Par ailleurs, on sait que <span>\\(Y^2 \\sim \\chi^2(1)\\)</span> par définition.</p>",
      "order": 7
    },
    {
      "id": "block_8",
      "type": "question",
      "latex": "Si $a > 0$, montrer que $X/a \\sim \\gamma(p, a\\theta)$.",
      "html": "<p>Si <span>\\(a &gt; 0\\)</span>, montrer que <span>\\(X/a \\sim \\gamma(p, a\\theta)\\)</span>.</p>",
      "order": 8
    },
    {
      "id": "block_9",
      "type": "reponse",
      "latex": "Pour toute fonction $\\Psi$ borélienne bornée, \n\\begin{align*}\nE(\\Psi(X/a)) &= \\frac{\\theta^p}{\\Gamma(p)} \\int_{0}^{\\infty} \\Psi(x/a)x^{p-1}e^{-\\theta x} dx\\\\\n&= \\frac{(a\\theta)^p}{\\Gamma(p)} \\int_{0}^{\\infty} \\Psi(x/a)(x/a)^{p-1}e^{-a\\theta x/a} \\frac{dx}{a}\\\\\n&= \\frac{(a\\theta)^p}{\\Gamma(p)} \\int_{0}^{\\infty} \\Psi(y)y^{p-1}e^{-a\\theta y} dy\n\\end{align*}\nd'où le résultat.",
      "html": "<p>Pour toute fonction <span>\\(\\Psi\\)</span> borélienne bornée,\n<span>\\[\\begin{align*}\nE(\\Psi(X/a)) &amp;= \\frac{\\theta^p}{\\Gamma(p)} \\int_{0}^{\\infty} \\Psi(x/a)x^{p-1}e^{-\\theta x} dx\\\\\n&amp;= \\frac{(a\\theta)^p}{\\Gamma(p)} \\int_{0}^{\\infty} \\Psi(x/a)(x/a)^{p-1}e^{-a\\theta x/a} \\frac{dx}{a}\\\\\n&amp;= \\frac{(a\\theta)^p}{\\Gamma(p)} \\int_{0}^{\\infty} \\Psi(y)y^{p-1}e^{-a\\theta y} dy\n\\end{align*}\\]</span>\nd’où le résultat.</p>",
      "order": 9
    },
    {
      "id": "block_10",
      "type": "question",
      "latex": "Soient $X$ et $Y$ deux v.a. indépendantes de lois respectives $\\gamma(p_1, \\theta)$ et $\\gamma(p_2, \\theta)$. Montrer que $X + Y \\sim \\gamma(p_1 + p_2, \\theta)$.",
      "html": "<p>Soient <span>\\(X\\)</span> et <span>\\(Y\\)</span> deux v.a. indépendantes de lois respectives <span>\\(\\gamma(p_1, \\theta)\\)</span> et <span>\\(\\gamma(p_2, \\theta)\\)</span>. Montrer que <span>\\(X + Y \\sim \\gamma(p_1 + p_2, \\theta)\\)</span>.</p>",
      "order": 10
    },
    {
      "id": "block_11",
      "type": "reponse",
      "latex": "Pour déterminer la loi de $X + Y$, on calcule sa fonction caractéristique $\\Phi_{X+Y}(t) = E[e^{it(X+Y)}]$. Grâce à l'indépendance, cette fonction est égale au produit des fonctions caractéristiques de $X$ et de $Y$ :\n\\begin{align*}\n\\Phi_{X+Y}(t) &= \\Phi_X(t) \\cdot \\Phi_Y(t)\\\\\n&= \\frac{1}{(1-i\\theta^{-1}t)^{p_1}} \\cdot \\frac{1}{(1-i\\theta^{-1}t)^{p_2}}\\\\\n&= \\frac{1}{(1-i\\theta^{-1}t)^{p_1+p_2}}\n\\end{align*}\n\nAinsi, $\\Phi_{X+Y}$ est la fonction caractéristique de la loi $\\gamma(p_1 + p_2, \\theta)$.",
      "html": "<p>Pour déterminer la loi de <span>\\(X + Y\\)</span>, on calcule sa fonction caractéristique <span>\\(\\Phi_{X+Y}(t) = E[e^{it(X+Y)}]\\)</span>. Grâce à l’indépendance, cette fonction est égale au produit des fonctions caractéristiques de <span>\\(X\\)</span> et de <span>\\(Y\\)</span> :\n<span>\\[\\begin{align*}\n\\Phi_{X+Y}(t) &amp;= \\Phi_X(t) \\cdot \\Phi_Y(t)\\\\\n&amp;= \\frac{1}{(1-i\\theta^{-1}t)^{p_1}} \\cdot \\frac{1}{(1-i\\theta^{-1}t)^{p_2}}\\\\\n&amp;= \\frac{1}{(1-i\\theta^{-1}t)^{p_1+p_2}}\n\\end{align*}\\]</span></p>\n<p>Ainsi, <span>\\(\\Phi_{X+Y}\\)</span> est la fonction caractéristique de la loi <span>\\(\\gamma(p_1 + p_2, \\theta)\\)</span>.</p>",
      "order": 11
    },
    {
      "id": "block_12",
      "type": "question",
      "latex": "Si $X_1, \\ldots, X_n$ sont $n$ variables aléatoires indépendantes de même loi $\\gamma(1, \\theta)$ (loi exponentielle de paramètre $\\theta$), donner la loi de la somme $S_n = X_1 + \\ldots + X_n$ et calculer $E(S_n)$ et $\\text{Var}(S_n)$.",
      "html": "<p>Si <span>\\(X_1, \\ldots, X_n\\)</span> sont <span>\\(n\\)</span> variables aléatoires indépendantes de même loi <span>\\(\\gamma(1, \\theta)\\)</span> (loi exponentielle de paramètre <span>\\(\\theta\\)</span>), donner la loi de la somme <span>\\(S_n = X_1 + \\ldots + X_n\\)</span> et calculer <span>\\(E(S_n)\\)</span> et <span>\\(\\text{Var}(S_n)\\)</span>.</p>",
      "order": 12
    },
    {
      "id": "block_13",
      "type": "reponse",
      "latex": "D'après la question précédente (et par une récurrence triviale), $S_n \\sim \\gamma(n, \\theta)$. En utilisant la question 2, nous avons donc \n\\begin{align*}\nE(S_n) &= \\frac{n}{\\theta},\\\\\n\\text{Var}(S_n) &= \\frac{n}{\\theta^2}.\n\\end{align*}",
      "html": "<p>D’après la question précédente (et par une récurrence triviale), <span>\\(S_n \\sim \\gamma(n, \\theta)\\)</span>. En utilisant la question 2, nous avons donc\n<span>\\[\\begin{align*}\nE(S_n) &amp;= \\frac{n}{\\theta},\\\\\n\\text{Var}(S_n) &amp;= \\frac{n}{\\theta^2}.\n\\end{align*}\\]</span></p>",
      "order": 13
    },
    {
      "id": "block_14",
      "type": "question",
      "latex": "Si $X_1, \\ldots, X_n$ sont $n$ variables aléatoires indépendantes de même loi $\\mathcal{N}(0, 1)$, donner la loi de $S'_n = X_1^2 + \\ldots + X_n^2$ et en déduire que $\\gamma(n/2, 1/2) = \\chi^2(n)$. Calculer $E(S'_n)$ et $\\text{Var}(S'_n)$.",
      "html": "<p>Si <span>\\(X_1, \\ldots, X_n\\)</span> sont <span>\\(n\\)</span> variables aléatoires indépendantes de même loi <span>\\(\\mathcal{N}(0, 1)\\)</span>, donner la loi de <span>\\(S&#39;_n = X_1^2 + \\ldots + X_n^2\\)</span> et en déduire que <span>\\(\\gamma(n/2, 1/2) = \\chi^2(n)\\)</span>. Calculer <span>\\(E(S&#39;_n)\\)</span> et <span>\\(\\text{Var}(S&#39;_n)\\)</span>.</p>",
      "order": 14
    },
    {
      "id": "block_15",
      "type": "reponse",
      "latex": "En utilisant la question 3, les $X^2_i$ sont i.i.d. de loi $\\gamma(1/2, 1/2)$. Ainsi, $S'_n \\sim \\gamma(n/2, 1/2)$. Comme nous savons par ailleurs que $S'_n \\sim \\chi^2(n)$ (par définition), nous avons $\\gamma(n/2, 1/2) = \\chi^2(n)$. En utilisant la question 2, on retrouve que \n\\begin{align*}\nE(S'_n) &= n,\\\\\n\\text{Var}(S'_n) &= 2n.\n\\end{align*}",
      "html": "<p>En utilisant la question 3, les <span>\\(X^2_i\\)</span> sont i.i.d. de loi <span>\\(\\gamma(1/2, 1/2)\\)</span>. Ainsi, <span>\\(S&#39;_n \\sim \\gamma(n/2, 1/2)\\)</span>. Comme nous savons par ailleurs que <span>\\(S&#39;_n \\sim \\chi^2(n)\\)</span> (par définition), nous avons <span>\\(\\gamma(n/2, 1/2) = \\chi^2(n)\\)</span>. En utilisant la question 2, on retrouve que\n<span>\\[\\begin{align*}\nE(S&#39;_n) &amp;= n,\\\\\n\\text{Var}(S&#39;_n) &amp;= 2n.\n\\end{align*}\\]</span></p>",
      "order": 15
    }
  ],
  "artifacts": {
    "tikz": [],
    "geogebra": [],
    "code": [],
    "video": null
  },
  "source_hash": "610da73038f741611c86c3496ac84fe2489f42d3a111fd330787bf857eeb6f77"
}