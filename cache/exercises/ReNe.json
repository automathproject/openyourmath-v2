{
  "uuid": "ReNe",
  "title": "OPTRN",
  "chapter": "Autre",
  "subchapter": "Autre",
  "theme": "réseaux de neurones",
  "difficulty": null,
  "author": "",
  "organization": "AMSCC",
  "video_id": "",
  "created_at": "2024-10-11",
  "updated_at": "2025-08-23T12:07:03.817Z",
  "content": [
    {
      "id": "block_1",
      "type": "text",
      "latex": "Soit le réseau de neurones multicouches décrit pas le graphe suivant:\n\n\\begin{center}\n\t\\begin{tikzpicture}[scale=1]\n\\def\\layersep{2cm}\n\\tikzstyle{every pin edge}=[thick]\n\\tikzstyle{neuron}=[circle,fill=black!25,minimum size=12pt,inner sep=0pt]\n\\tikzstyle{entree}=[];\n\\tikzstyle{input neuron}=[neuron, fill=green!50];\n\\tikzstyle{output neuron}=[neuron, fill=red!50];\n\\tikzstyle{hidden neuron}=[neuron, fill=blue!50];\n\\tikzstyle{annot} = [text width=4em, text centered]\n\n\n\\node[entree,blue] (E-1) at (-\\layersep,-0.5) {$1$};\n\\node[entree,blue] (E-2) at (-\\layersep,-2.5) {$x$};\n\\node[entree,blue] (E-3) at (-\\layersep,-5) {$1$};\n\n\n\n\\node[input neuron] (I-1) at (0,-1.5) {};\n\\node[input neuron] (I-3) at (0,-3.75) {};\n\n\\node[below right=0.8ex,scale=0.7] at (I-1) {$\\Sigma$};\n\n\\node[below right=0.8ex,scale=0.7] at (I-3) {$\\Sigma$};\n\n\\node[below right=0.8ex,scale=0.7] at (I-1) {};\n\\node[below right=0.8ex,scale=0.7] at (I-3) {};\n\n\n\n\n\n\n\n\\node[hidden neuron] (O) at (\\layersep,-3.75 cm) {};\n\\node[hidden neuron] (P) at (\\layersep,-1.5 cm) {};\n\\node[above right=0.8ex,scale=0.7] at (O) {$h_{12}$};\n\\node[right=0.5ex,scale=0.7] at (P) {$h_{11}$};\n\n\n\\path[thick] (E-1) edge node[pos=0.5,above,scale=0.7]{$w_{1}$} (I-1) ;\n\\path[thick] (E-2) edge node[pos=0.5,above left,scale=0.7]{$w_{2}$} (I-1);\n\\path[thick] (E-2) edge node[pos=0.5,above,scale=0.7]{$w_4$} (I-3);\n\\path[thick] (E-3) edge node[pos=0.5,above,scale=0.7]{$w_3$} (I-3);\n\\path[thick] (I-1) edge node[pos=0.5,above,scale=0.7]{$f_{11}$} (P);\n\\path[thick] (I-3) edge node[pos=0.5,below,scale=0.7]{$f_{12}$}(O);\n\\node[below right=0.8ex,scale=0.5] at (O) {$\\text{Sigmoide}$};\n\\node[below =0.8ex,scale=0.5] at (P) {$\\text{Sigmoide}$};\n\n\\node[hidden neuron] (Q) at (2*\\layersep,-2.5 cm) {};\n\\node[output neuron] (R) at (3*\\layersep,-2.5 cm) {};\n\\node[below right=0.8ex,scale=0.7] at (R) {$\\text{Id}$};\n\\node[input neuron] (I-4) at (2.5,-0.5) {$1$};\n\\path[thick] (O) edge node[pos=0.6,above,scale=0.7]{$w_{7}$} (Q) ;\n\\node[below right=0.8ex,scale=0.7] at (Q) {$\\Sigma$};\n\\path[thick] (I-4) edge node[pos=0.5,above,scale=0.7]{$w_{5}$} (Q) ;\n\\path[thick] (Q) edge node[pos=0.5,above,scale=0.7]{$f_{21}$} (R);\n\\path[thick] (P) edge node[pos=0.5,above,scale=0.7]{$w_{6}$} (Q) ;\n\n\\draw[->,thick] (R)-- ++(2,0) node[right,blue]{$\\hat{y}$};\n \n     \n\n\n\n\n\\end{tikzpicture}  \n\\end{center}",
      "html": "<p>Soit le réseau de neurones multicouches décrit pas le graphe suivant:</p>",
      "order": 1
    },
    {
      "id": "block_2",
      "type": "question",
      "latex": "Donner les formules qui déterminent les sorties intermédiaires $f_{11},\\,f_{12},\\,h_{11},\\,h_{12}$ et $f_{21}$ ainsi que la sortie finale $\\hat{y}$.",
      "html": "<p>Donner les formules qui déterminent les sorties intermédiaires <span>\\(f_{11},\\,f_{12},\\,h_{11},\\,h_{12}\\)</span> et <span>\\(f_{21}\\)</span> ainsi que la sortie finale <span>\\(\\hat{y}\\)</span>.</p>",
      "order": 2
    },
    {
      "id": "block_3",
      "type": "reponse",
      "latex": "\\[\nf_{11} = w_2 x + w_1\n\\]\n\\[\nf_{12} = w_4 x + w_3\n\\]\n\\[\nh_{11} = \\sigma(f_{11}) = \\frac{1}{1 + e^{-f_{11}}}\n\\]\n\\[\nh_{12} = \\sigma(f_{12}) = \\frac{1}{1 + e^{-f_{12}}}\n\\]\n\\[\n\\hat{y} = f_{21} = w_6 h_{11} + w_7 h_{12} + w_5\n\\]",
      "html": "<p><span>\\[f_{11} = w_2 x + w_1\\]</span>\n<span>\\[f_{12} = w_4 x + w_3\\]</span>\n<span>\\[h_{11} = \\sigma(f_{11}) = \\frac{1}{1 + e^{-f_{11}}}\\]</span>\n<span>\\[h_{12} = \\sigma(f_{12}) = \\frac{1}{1 + e^{-f_{12}}}\\]</span>\n<span>\\[\\hat{y} = f_{21} = w_6 h_{11} + w_7 h_{12} + w_5\\]</span></p>",
      "order": 3
    },
    {
      "id": "block_4",
      "type": "question",
      "latex": "On pose la fonction d'erreur $E(w)=(y-\\hat{y})^2.$ En appliquant l'algorithme de backpropagation (méthode du Gradient appliqué au réseau de neurones), déterminer les dérivées partielles $\\frac{\\partial E(w)}{\\partial w_j}$ puis $\\frac{\\partial \\hat{y}}{\\partial w_j}$. En déduire les expressions des mises à jour des paramètres $\\Delta w_j$ (variation des poids) pour $j=1,\\cdots{},7$.",
      "html": "<p>On pose la fonction d’erreur <span>\\(E(w)=(y-\\hat{y})^2.\\)</span> En appliquant l’algorithme de backpropagation (méthode du Gradient appliqué au réseau de neurones), déterminer les dérivées partielles <span>\\(\\frac{\\partial E(w)}{\\partial w_j}\\)</span> puis <span>\\(\\frac{\\partial \\hat{y}}{\\partial w_j}\\)</span>. En déduire les expressions des mises à jour des paramètres <span>\\(\\Delta w_j\\)</span> (variation des poids) pour <span>\\(j=1,\\cdots{},7\\)</span>.</p>",
      "order": 4
    },
    {
      "id": "block_5",
      "type": "reponse",
      "latex": "La fonction d’erreur est donnée par :\n\\[\nE(\\mathbf{w}) = (y - \\hat{y})^2\n\\]\n\nDonc, on aura :\n\\[\n\\frac{\\partial E(\\mathbf{w})}{\\partial w_j} = -2(y - \\hat{y}) \\frac{\\partial \\hat{y}}{\\partial w_j}\n\\]\n\nD’après la propagation en avant, on a : $\\hat{y} = f_{21} = w_6 h_{11} + w_7 h_{12} + w_5$.  \nLes dérivées partielles $\\frac{\\partial \\hat{y}}{\\partial w_j}$ peuvent être calculées comme suit :\n\\[\n\\frac{\\partial \\hat{y}}{\\partial w_5} = 1, \\quad\n\\frac{\\partial \\hat{y}}{\\partial w_6} = h_{11}, \\quad\n\\frac{\\partial \\hat{y}}{\\partial w_7} = h_{12}\n\\]\n\nPour les autres paramètres :\n\\[\n\\frac{\\partial \\hat{y}}{\\partial w_1} = \\frac{\\partial \\hat{y}}{\\partial h_{11}} \\times \\frac{\\partial h_{11}}{\\partial f_{11}} \\times \\frac{\\partial f_{11}}{\\partial w_1} = w_6 h_{11}(1 - h_{11})\n\\]\n\\[\n\\frac{\\partial \\hat{y}}{\\partial w_2} = w_6 h_{11}(1 - h_{11}) x\n\\]\n\\[\n\\frac{\\partial \\hat{y}}{\\partial w_3} = w_7 h_{12}(1 - h_{12})\n\\]\n\\[\n\\frac{\\partial \\hat{y}}{\\partial w_4} = w_7 h_{12}(1 - h_{12}) x\n\\]\n\nEn fin, la mise à jour de chaque paramètre $\\Delta w_j$ est donnée par :\n\\[\n\\Delta w_j = \\alpha (y - \\hat{y}) \\frac{\\partial \\hat{y}}{\\partial w_j}\n\\]",
      "html": "<p>La fonction d’erreur est donnée par :\n<span>\\[E(\\mathbf{w}) = (y - \\hat{y})^2\\]</span></p>\n<p>Donc, on aura :\n<span>\\[\\frac{\\partial E(\\mathbf{w})}{\\partial w_j} = -2(y - \\hat{y}) \\frac{\\partial \\hat{y}}{\\partial w_j}\\]</span></p>\n<p>D’après la propagation en avant, on a : <span>\\(\\hat{y} = f_{21} = w_6 h_{11} + w_7 h_{12} + w_5\\)</span>.\nLes dérivées partielles <span>\\(\\frac{\\partial \\hat{y}}{\\partial w_j}\\)</span> peuvent être calculées comme suit :\n<span>\\[\\frac{\\partial \\hat{y}}{\\partial w_5} = 1, \\quad\n\\frac{\\partial \\hat{y}}{\\partial w_6} = h_{11}, \\quad\n\\frac{\\partial \\hat{y}}{\\partial w_7} = h_{12}\\]</span></p>\n<p>Pour les autres paramètres :\n<span>\\[\\frac{\\partial \\hat{y}}{\\partial w_1} = \\frac{\\partial \\hat{y}}{\\partial h_{11}} \\times \\frac{\\partial h_{11}}{\\partial f_{11}} \\times \\frac{\\partial f_{11}}{\\partial w_1} = w_6 h_{11}(1 - h_{11})\\]</span>\n<span>\\[\\frac{\\partial \\hat{y}}{\\partial w_2} = w_6 h_{11}(1 - h_{11}) x\\]</span>\n<span>\\[\\frac{\\partial \\hat{y}}{\\partial w_3} = w_7 h_{12}(1 - h_{12})\\]</span>\n<span>\\[\\frac{\\partial \\hat{y}}{\\partial w_4} = w_7 h_{12}(1 - h_{12}) x\\]</span></p>\n<p>En fin, la mise à jour de chaque paramètre <span>\\(\\Delta w_j\\)</span> est donnée par :\n<span>\\[\\Delta w_j = \\alpha (y - \\hat{y}) \\frac{\\partial \\hat{y}}{\\partial w_j}\\]</span></p>",
      "order": 5
    }
  ],
  "artifacts": {
    "tikz": [
      {
        "id": "tikz_0",
        "type": "tikz",
        "url": "/artifacts/tikz/ReNe-tikz-0.svg",
        "latex": "\\begin{tikzpicture}[scale=1]\n\\def\\layersep{2cm}\n\\tikzstyle{every pin edge}=[thick]\n\\tikzstyle{neuron}=[circle,fill=black!25,minimum size=12pt,inner sep=0pt]\n\\tikzstyle{entree}=[];\n\\tikzstyle{input neuron}=[neuron, fill=green!50];\n\\tikzstyle{output neuron}=[neuron, fill=red!50];\n\\tikzstyle{hidden neuron}=[neuron, fill=blue!50];\n\\tikzstyle{annot} = [text width=4em, text centered]\n\n% Entree\n\\node[entree,blue] (E-1) at (-\\layersep,-0.5) {$1$};\n\\node[entree,blue] (E-2) at (-\\layersep,-2.5) {$x$};\n\\node[entree,blue] (E-3) at (-\\layersep,-5) {$1$};\n\n% Premiere couche\n%\\node[input neuron] (I-1) at (0,-1.25) {};\n\\node[input neuron] (I-1) at (0,-1.5) {};\n\\node[input neuron] (I-3) at (0,-3.75) {};\n\n\\node[below right=0.8ex,scale=0.7] at (I-1) {$\\Sigma$};\n%\\node[above right=0.8ex,scale=0.7] at (I-2) {$H$};\n\\node[below right=0.8ex,scale=0.7] at (I-3) {$\\Sigma$};\n\n\\node[below right=0.8ex,scale=0.7] at (I-1) {};\n\\node[below right=0.8ex,scale=0.7] at (I-3) {};\n%\\node[below right=0.8ex,scale=0.7] at (I-2) {};\n\n% \\node[above right=0.8ex,blue] at (I-1) {$s_1$};\n% \\node[above right=0.8ex,blue] at (I-2) {$s_2$};\n% \\node[above right=0.8ex,blue] at (I-3) {$s_3$};\n\n%Seconde couche et sortie\n\\node[hidden neuron] (O) at (\\layersep,-3.75 cm) {};\n\\node[hidden neuron] (P) at (\\layersep,-1.5 cm) {};\n\\node[above right=0.8ex,scale=0.7] at (O) {$h_{12}$};\n\\node[right=0.5ex,scale=0.7] at (P) {$h_{11}$};\n\n% Arrete et poids\n\\path[thick] (E-1) edge node[pos=0.5,above,scale=0.7]{$w_{1}$} (I-1) ;\n\\path[thick] (E-2) edge node[pos=0.5,above left,scale=0.7]{$w_{2}$} (I-1);\n\\path[thick] (E-2) edge node[pos=0.5,above,scale=0.7]{$w_4$} (I-3);\n\\path[thick] (E-3) edge node[pos=0.5,above,scale=0.7]{$w_3$} (I-3);\n\\path[thick] (I-1) edge node[pos=0.5,above,scale=0.7]{$f_{11}$} (P);\n\\path[thick] (I-3) edge node[pos=0.5,below,scale=0.7]{$f_{12}$}(O);\n\\node[below right=0.8ex,scale=0.5] at (O) {$\\text{Sigmoide}$};\n\\node[below =0.8ex,scale=0.5] at (P) {$\\text{Sigmoide}$};\n%3eme couche et sortie\n\\node[hidden neuron] (Q) at (2*\\layersep,-2.5 cm) {};\n\\node[output neuron] (R) at (3*\\layersep,-2.5 cm) {};\n\\node[below right=0.8ex,scale=0.7] at (R) {$\\text{Id}$};\n\\node[input neuron] (I-4) at (2.5,-0.5) {$1$};\n\\path[thick] (O) edge node[pos=0.6,above,scale=0.7]{$w_{7}$} (Q) ;\n\\node[below right=0.8ex,scale=0.7] at (Q) {$\\Sigma$};\n\\path[thick] (I-4) edge node[pos=0.5,above,scale=0.7]{$w_{5}$} (Q) ;\n\\path[thick] (Q) edge node[pos=0.5,above,scale=0.7]{$f_{21}$} (R);\n\\path[thick] (P) edge node[pos=0.5,above,scale=0.7]{$w_{6}$} (Q) ;\n%\\path[thick] (E-1) edge node[pos=0.8,above,scale=0.7]{$w_{1}$} (I-1) ;\n\\draw[->,thick] (R)-- ++(2,0) node[right,blue]{$\\hat{y}$};\n %  \\node[hidden neuron] (N) at (2*\\layersep,-2 cm) {}; % Nouvel neurone de la nouvelle couche\n     %           \\node[below right=0.8ex,scale=0.7] at (N) {$h_{21}$}; % Nouveau neurone\n\n% Sortie\n%\\draw[->,thick] (O)-- ++(1,0) node[right,blue]{$F(x,y)$};\n\n\\end{tikzpicture}"
      }
    ],
    "geogebra": [],
    "code": [],
    "video": null
  },
  "source_hash": "57f877005c4387c3716762583b719b700586c3d2285e81cbc303bb689c511439"
}