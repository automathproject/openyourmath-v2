{
  "uuid": "DEZs",
  "title": "Estimateur et intervalle de confiance",
  "chapter": "Statistique",
  "subchapter": "Tests d'hypothèses, intervalle de confiance",
  "theme": "statistiques, estimateurs, intervalle de confiance",
  "difficulty": null,
  "author": "",
  "organization": "AMSCC",
  "video_id": "",
  "created_at": "2022-09-24",
  "updated_at": "2025-08-22T13:02:31.954Z",
  "content": [
    {
      "id": "block_1",
      "type": "text",
      "latex": "Soient $X_1,...,X_n$ des variables aléatoires indépendantes et de même loi ayant pour densité :\n\t$$f_\\theta \\colon x \\mapsto \\left\\{\n\t\\begin{array}{ll}\n\t\t\\frac{1}{2}(1+\\theta x) & \\mbox{si } -1 \\leq x \\leq 1 \\\\\n\t\t0 & \\mbox{sinon.}\n\t\\end{array}\n\t\\right.$$\n\toù $\\theta \\in [-1;1]$ est un paramètre.",
      "html": "<p>Soient <span>\\(X_1,...,X_n\\)</span> des variables aléatoires indépendantes et de même loi ayant pour densité :\n<span>\\[f_\\theta \\colon x \\mapsto \\left\\{\n    \\begin{array}{ll}\n        \\frac{1}{2}(1+\\theta x) &amp; \\mbox{si } -1 \\leq x \\leq 1 \\\\\n        0 &amp; \\mbox{sinon.}\n    \\end{array}\n    \\right.\\]</span>\noù <span>\\(\\theta \\in [-1;1]\\)</span> est un paramètre.</p>",
      "order": 1
    },
    {
      "id": "block_2",
      "type": "question",
      "latex": "Montrer que pour tout $\\theta \\in [-1;1]$, $f_\\theta $ est une densité de probabilité.",
      "html": "<p>Montrer que pour tout <span>\\(\\theta \\in [-1;1]\\)</span>, <span>\\(f_\\theta\\)</span> est une densité de probabilité.</p>",
      "order": 2
    },
    {
      "id": "block_3",
      "type": "reponse",
      "latex": "Le fait que $\\theta \\in [-1;1]$ garantit que $f_{\\theta}(x) \\geq 0$ pour tout $x \\in [-1;1]$. De plus, \n\t\t$$\\begin{align*}\n\t\t\t\\int f_\\theta(x) dx &= \\int_{-1}^{1} \\frac{1}{2}(1+\\theta x) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(1+0) dx \\quad \\text{ par imparité de x} \\\\\n\t\t\t&= 1\n\t\t\\end{align*}$$\t\n\t\tDonc $f_{\\theta}$ définit une bien une densité de probabilité.",
      "html": "<p>Le fait que <span>\\(\\theta \\in [-1;1]\\)</span> garantit que <span>\\(f_{\\theta}(x) \\geq 0\\)</span> pour tout <span>\\(x \\in [-1;1]\\)</span>. De plus,\n<span>\\[\\begin{align*}\n            \\int f_\\theta(x) dx &amp;= \\int_{-1}^{1} \\frac{1}{2}(1+\\theta x) dx \\\\\n            &amp;= \\int_{-1}^{1} \\frac{1}{2}(1+0) dx \\quad \\text{ par imparité de x} \\\\\n            &amp;= 1\n        \\end{align*}\\]</span>\nDonc <span>\\(f_{\\theta}\\)</span> définit une bien une densité de probabilité.</p>",
      "order": 3
    },
    {
      "id": "block_4",
      "type": "question",
      "latex": "Calculer $\\mathbb{E}(X_1)$ et $\\mathbb{V}(X_1)$. En déduire l'espérance et la variance de la variable aléatoire $\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$.",
      "html": "<p>Calculer <span>\\(\\mathbb{E}(X_1)\\)</span> et <span>\\(\\mathbb{V}(X_1)\\)</span>. En déduire l’espérance et la variance de la variable aléatoire <span>\\(\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i\\)</span>.</p>",
      "order": 4
    },
    {
      "id": "block_5",
      "type": "reponse",
      "latex": "On calcule les moments d'ordre 1 et 2 de la variable à densité $X_1$ :\n\t\t$$\\begin{align*}\n\t\t\t\\mathbb{E}(X_1) &= \\int x f_\\theta(x) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(x+\\theta x^2) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(\\theta x^2) dx \\quad \\text{ par imparité de $x$} \\\\\n\t\t\t&= 2\\int_{0}^{1} \\frac{1}{2}(\\theta x^2) dx \\quad \\text{ par parité de $x^2$} \\\\\n\t\t\t&= \\frac{\\theta}{3}\n\t\t\\end{align*}$$\n\t\tDe même, \t\t\n\t\t$$\\begin{align*}\n\t\t\t\\mathbb{E}(X_1^2) &= \\int x^2 f_\\theta(x) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(x^2+\\theta x^3) dx \\\\\n\t\t\t&= \\int_{-1}^{1} \\frac{1}{2}(x^2) dx \\quad \\text{ par imparité de $x^3$} \\\\\n\t\t\t&= \\int_{0}^{1}  x^2 dx \\quad \\text{ par parité de $x^2$} \\\\\n\t\t\t&= \\frac{1}{3}\n\t\t\\end{align*}$$\n\t\t\n\t\tAvec la formule de Koenig Huygens, on en déduit que \n\t\t$$\\mathbb{V}(X_1) = \\mathbb{E}(X_1^2) - \t\\mathbb{E}(X_1)^2 = \\frac{1}{3}-\\frac{\\theta^2}{9} = \\frac{3-\\theta^2}{9}$$",
      "html": "<p>On calcule les moments d’ordre 1 et 2 de la variable à densité <span>\\(X_1\\)</span> :\n<span>\\[\\begin{align*}\n            \\mathbb{E}(X_1) &amp;= \\int x f_\\theta(x) dx \\\\\n            &amp;= \\int_{-1}^{1} \\frac{1}{2}(x+\\theta x^2) dx \\\\\n            &amp;= \\int_{-1}^{1} \\frac{1}{2}(\\theta x^2) dx \\quad \\text{ par imparité de $x$} \\\\\n            &amp;= 2\\int_{0}^{1} \\frac{1}{2}(\\theta x^2) dx \\quad \\text{ par parité de $x^2$} \\\\\n            &amp;= \\frac{\\theta}{3}\n        \\end{align*}\\]</span>\nDe même,\n<span>\\[\\begin{align*}\n            \\mathbb{E}(X_1^2) &amp;= \\int x^2 f_\\theta(x) dx \\\\\n            &amp;= \\int_{-1}^{1} \\frac{1}{2}(x^2+\\theta x^3) dx \\\\\n            &amp;= \\int_{-1}^{1} \\frac{1}{2}(x^2) dx \\quad \\text{ par imparité de $x^3$} \\\\\n            &amp;= \\int_{0}^{1}  x^2 dx \\quad \\text{ par parité de $x^2$} \\\\\n            &amp;= \\frac{1}{3}\n        \\end{align*}\\]</span></p>\n<p>Avec la formule de Koenig Huygens, on en déduit que\n<span>\\[\\mathbb{V}(X_1) = \\mathbb{E}(X_1^2) -     \\mathbb{E}(X_1)^2 = \\frac{1}{3}-\\frac{\\theta^2}{9} = \\frac{3-\\theta^2}{9}\\]</span></p>",
      "order": 5
    },
    {
      "id": "block_6",
      "type": "question",
      "latex": "On pose $T_n = \\frac{3}{n} \\sum_{i=1}^{n} X_i$. Montrer que $T$ est un estimateur sans biais et convergent de $\\theta$.",
      "html": "<p>On pose <span>\\(T_n = \\frac{3}{n} \\sum_{i=1}^{n} X_i\\)</span>. Montrer que <span>\\(T\\)</span> est un estimateur sans biais et convergent de <span>\\(\\theta\\)</span>.</p>",
      "order": 6
    },
    {
      "id": "block_7",
      "type": "reponse",
      "latex": "On calcule par linéarité de l'espérance : $\\mathbb{E}(T_n) = \\frac{3}{n} \\times n \\mathbb{E}(X_1) = \\theta$. Donc le biais de $T_n$ est \n\t\t$B(T_n) = \\mathbb{E}(T_n-\\theta) =\\theta - \\theta = 0$.\n\t\t\n\t\tDe plus, par propriétés de la variance et indépendance, \n\t\t$$\\mathbb{V}(T_n) =  \\frac{9}{n^2} \\times n \\times \\mathbb{V}(X_1) = \\frac{3-\\theta^2}{n}$$\n\t\tOr $EQM(T_n) = \\mathbb{V}(T_n) + B(T_n)^2$ donc $EQM(T_n) = \\frac{3-\\theta^2}{n} \\xrightarrow[n \\to +\\infty]{} 0$ : cela prouve que l'estimateur $T_n$ est convergent.",
      "html": "<p>On calcule par linéarité de l’espérance : <span>\\(\\mathbb{E}(T_n) = \\frac{3}{n} \\times n \\mathbb{E}(X_1) = \\theta\\)</span>. Donc le biais de <span>\\(T_n\\)</span> est\n<span>\\(B(T_n) = \\mathbb{E}(T_n-\\theta) =\\theta - \\theta = 0\\)</span>.</p>\n<p>De plus, par propriétés de la variance et indépendance,\n<span>\\[\\mathbb{V}(T_n) =  \\frac{9}{n^2} \\times n \\times \\mathbb{V}(X_1) = \\frac{3-\\theta^2}{n}\\]</span>\nOr <span>\\(EQM(T_n) = \\mathbb{V}(T_n) + B(T_n)^2\\)</span> donc <span>\\(EQM(T_n) = \\frac{3-\\theta^2}{n} \\xrightarrow[n \\to +\\infty]{} 0\\)</span> : cela prouve que l’estimateur <span>\\(T_n\\)</span> est convergent.</p>",
      "order": 7
    },
    {
      "id": "block_8",
      "type": "question",
      "latex": "\\`A l'aide du Théorème Central Limite, donner une approximation de la loi de $T_n$.",
      "html": "<p>À l’aide du Théorème Central Limite, donner une approximation de la loi de <span>\\(T_n\\)</span>.</p>",
      "order": 8
    },
    {
      "id": "block_9",
      "type": "reponse",
      "latex": "On pose $\\mu = \\mathbb{E}(X_1)$ et $\\sigma = \\sqrt{\\mathbb{V}(X_1)}$. Les variables $(X_i)$ sont iid, admettent une espérance et une variance donc d'après le théorème central limite, la variable \n\t\t$$\\frac{\\sum_{i=1}^n X_i - n\\mu}{\\sigma\\sqrt{n} }$$ converge en loi vers une loi normale $\\mathcal{N}(0,1)$.\n\t\tEn réécrivant, cela revient à dire que \t\n\t\t$$\\frac{\\frac{3}{n}\\sum_{i=1}^n X_i - 3\\mu}{3\\frac{\\sigma}{\\sqrt{n}} } = \\frac{T_n-\\theta}{\\sqrt{\\frac{3-\\theta^2}{n}}}$$ converge en loi vers une loi normale $\\mathcal{N}(0,1)$.\n\t\t\n\t\tSi $n$ est grand ($n \\geq 30$), cela revient à dire que $T_n$ suit approximativement une loi normale $\\mathcal{N}(\\theta, \\sigma^2 = \\frac{3-\\theta^2}{n})$.",
      "html": "<p>On pose <span>\\(\\mu = \\mathbb{E}(X_1)\\)</span> et <span>\\(\\sigma = \\sqrt{\\mathbb{V}(X_1)}\\)</span>. Les variables <span>\\((X_i)\\)</span> sont iid, admettent une espérance et une variance donc d’après le théorème central limite, la variable\n<span>\\[\\frac{\\sum_{i=1}^n X_i - n\\mu}{\\sigma\\sqrt{n} }\\]</span> converge en loi vers une loi normale <span>\\(\\mathcal{N}(0,1)\\)</span>.\nEn réécrivant, cela revient à dire que\n<span>\\[\\frac{\\frac{3}{n}\\sum_{i=1}^n X_i - 3\\mu}{3\\frac{\\sigma}{\\sqrt{n}} } = \\frac{T_n-\\theta}{\\sqrt{\\frac{3-\\theta^2}{n}}}\\]</span> converge en loi vers une loi normale <span>\\(\\mathcal{N}(0,1)\\)</span>.</p>\n<p>Si <span>\\(n\\)</span> est grand (<span>\\(n \\geq 30\\)</span>), cela revient à dire que <span>\\(T_n\\)</span> suit approximativement une loi normale <span>\\(\\mathcal{N}(\\theta, \\sigma^2 = \\frac{3-\\theta^2}{n})\\)</span>.</p>",
      "order": 9
    },
    {
      "id": "block_10",
      "type": "question",
      "latex": "Démontrer qu'il existe une constante $M_n$ ne dépendant pas de $\\theta$ telle que si $\\lambda >0$, \n\t\t$$\\PP(|T_n-\\theta| < \\lambda) \\geq 1-\\frac{M_n}{\\lambda^2}$$",
      "html": "<p>Démontrer qu’il existe une constante <span>\\(M_n\\)</span> ne dépendant pas de <span>\\(\\theta\\)</span> telle que si <span>\\(\\lambda &gt;0\\)</span>,\n<span>\\[\\PP(|T_n-\\theta| &lt; \\lambda) \\geq 1-\\frac{M_n}{\\lambda^2}\\]</span></p>",
      "order": 10
    },
    {
      "id": "block_11",
      "type": "reponse",
      "latex": "D'après l'inégalité de Bienaymé Tchebichev, \n\t\t$$\\PP(|T_n-\\mathbb{E}(T_n)| \\geq  \\lambda) \\leq \\frac{\\mathbb{V}(T_n)}{\\lambda^2}$$\n\t\td'où $$\\PP(|T_n-\\theta| \\geq \\lambda) \\leq \\frac{3-\\theta^2}{n\\lambda^2} \\leq \\frac{3}{n\\lambda^2} = \\frac{M_n}{\\lambda^2}$$\n\t\ten posant $M_n = \\frac{3}{n}$.  Par passage au complémentaire, on obtient finalement :\n\t\t$$\\PP(|T_n-\\theta| < \\lambda) \\geq 1-\\frac{3}{n\\lambda^2}$$",
      "html": "<p>D’après l’inégalité de Bienaymé Tchebichev,\n<span>\\[\\PP(|T_n-\\mathbb{E}(T_n)| \\geq  \\lambda) \\leq \\frac{\\mathbb{V}(T_n)}{\\lambda^2}\\]</span>\nd’où <span>\\[\\PP(|T_n-\\theta| \\geq \\lambda) \\leq \\frac{3-\\theta^2}{n\\lambda^2} \\leq \\frac{3}{n\\lambda^2} = \\frac{M_n}{\\lambda^2}\\]</span>\nen posant <span>\\(M_n = \\frac{3}{n}\\)</span>. Par passage au complémentaire, on obtient finalement :\n<span>\\[\\PP(|T_n-\\theta| &lt; \\lambda) \\geq 1-\\frac{3}{n\\lambda^2}\\]</span></p>",
      "order": 11
    },
    {
      "id": "block_12",
      "type": "question",
      "latex": "Déterminer un intervalle de  confiance permettant d'estimer $\\theta$ avec une confiance d'au moins $95\\%$.",
      "html": "<p>Déterminer un intervalle de confiance permettant d’estimer <span>\\(\\theta\\)</span> avec une confiance d’au moins <span>\\(95\\%\\)</span>.</p>",
      "order": 12
    },
    {
      "id": "block_13",
      "type": "reponse",
      "latex": "On cherche un intervalle $I$ tel que $\\PP(\\theta \\in I) \\geq 0{,}95$. Or d'après ce qui précède,\n\t\t\n\t\t$$\\begin{align*}\n\t\t\t\\PP(|T_n-\\theta| < \\lambda) \\geq 1-\\frac{3}{n\\lambda^2} &\\iff \\PP(-\\lambda < T_n-\\theta < \\lambda ) \\geq 1-\\frac{3}{n\\lambda^2} \\\\\n\t\t\t&\\iff\t\\PP( \\theta \\in ]T_n-\\lambda ; T_n + \\lambda [) \\geq 1-\\frac{3}{n\\lambda^2} \t\n\t\t\\end{align*}$$ \n\t\tOr \t$1-\\frac{3}{n\\lambda^2} = 0{,}95 \\iff \\frac{3}{n\\lambda^2} = 0{,}05 \\iff \\lambda^2 = \\frac{3}{0{,}05 n}$\n\t\tdonc \n\t\t$$\\PP\\left( \\theta \\in \\left]T_n - \\sqrt{\\frac{3}{0{,}05 n}} ; T_n + \\sqrt{\\frac{3}{0{,}05 n}}  \\right[\\right) \\geq 0{,}95$$\n\t\td'où l'intervalle de confiance $I = \\left]T_n - \\sqrt{\\frac{3}{0{,}05 n}} ; T_n + \\sqrt{\\frac{3}{0{,}05 n}}  \\right[$.",
      "html": "<p>On cherche un intervalle <span>\\(I\\)</span> tel que <span>\\(\\PP(\\theta \\in I) \\geq 0{,}95\\)</span>. Or d’après ce qui précède,</p>\n<p><span>\\[\\begin{align*}\n            \\PP(|T_n-\\theta| &lt; \\lambda) \\geq 1-\\frac{3}{n\\lambda^2} &amp;\\iff \\PP(-\\lambda &lt; T_n-\\theta &lt; \\lambda ) \\geq 1-\\frac{3}{n\\lambda^2} \\\\\n            &amp;\\iff   \\PP( \\theta \\in ]T_n-\\lambda ; T_n + \\lambda [) \\geq 1-\\frac{3}{n\\lambda^2}     \n        \\end{align*}\\]</span>\nOr <span>\\(1-\\frac{3}{n\\lambda^2} = 0{,}95 \\iff \\frac{3}{n\\lambda^2} = 0{,}05 \\iff \\lambda^2 = \\frac{3}{0{,}05 n}\\)</span>\ndonc\n<span>\\[\\PP\\left( \\theta \\in \\left]T_n - \\sqrt{\\frac{3}{0{,}05 n}} ; T_n + \\sqrt{\\frac{3}{0{,}05 n}}  \\right[\\right) \\geq 0{,}95\\]</span>\nd’où l’intervalle de confiance <span>\\(I = \\left]T_n - \\sqrt{\\frac{3}{0{,}05 n}} ; T_n + \\sqrt{\\frac{3}{0{,}05 n}}  \\right[\\)</span>.</p>",
      "order": 13
    }
  ],
  "artifacts": {
    "tikz": [],
    "geogebra": [],
    "code": [],
    "video": null
  },
  "source_hash": "e4ecfdc6cf873b23b5f3afb8dd1cf25d5015ac868dbe4ecf5e571f4375bd1bfa"
}